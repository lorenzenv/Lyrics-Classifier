{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Project - Spiced 2022 - Valentin Lorenzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and cleaning the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libaries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import csv\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lady Gaga Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gaga lyric links\n",
    "\n",
    "all_of_gaga = requests.get('https://www.lyrics.com/artist/Lady-Gaga').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list out of gaga lyric links\n",
    "\n",
    "gaga_songlinks = re.findall(pattern='a href=\"(/lyric/.{9})', string=all_of_gaga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicates in gaga lyrics list\n",
    "\n",
    "gaga_songlinks = list(dict.fromkeys(gaga_songlinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to gaga lyrics\n",
    "\n",
    "gaga_songlinks_final = [\"www.lyrics.com/\" + x for x in gaga_songlinks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut list short to first 100 songs\n",
    "\n",
    "gaga_songlinks_final = gaga_songlinks_final[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download lyrics\n",
    "\n",
    "for songlink in gaga_songlinks_final:\n",
    "    song_number = re.findall(pattern='(\\d{6,9})', string=songlink)\n",
    "    print(songlink)\n",
    "    f = open(f\"gaga_lyrics/{song_number}.txt\", \"w\")\n",
    "    song_html = requests.get(songlink).text\n",
    "    f.write(song_html)\n",
    "    f.close()\n",
    "    print (song_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put lyrics into list\n",
    "\n",
    "gaga_lyrics = []\n",
    "\n",
    "for fn in os.listdir('gaga_lyrics/'):\n",
    "     text = open('gaga_lyrics/' + fn).read()\n",
    "     gaga_soup = BeautifulSoup(text, 'html.parser')\n",
    "     #print (gaga_soup.type)\n",
    "     lyric = gaga_soup.find_all('pre',{\"class\":\"lyric-body\"})\n",
    "     gaga_lyrics.append(lyric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up lyrics in list\n",
    "\n",
    "cleaner = re.compile('<.*?>') \n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleantext = re.sub(cleaner, '', raw_html)\n",
    "  return cleantext\n",
    "\n",
    "gaga_lyrics_clean = []\n",
    "\n",
    "for x in gaga_lyrics:\n",
    "    x_clean = cleanhtml(str(x))\n",
    "    x_clean = re.sub('[^A-Za-z\\s]+', '', x_clean)\n",
    "    gaga_lyrics_clean.append(x_clean.lower().replace('\\n', ' ').replace(\"\\'\", \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thundercat Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get thundercat lyric links\n",
    "\n",
    "all_of_thundercat = requests.get('https://www.lyrics.com/artist/Thundercat/2127533').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list out of thundercat lyric links\n",
    "\n",
    "thundercat_songlinks = re.findall(pattern='a href=\"(/lyric/.{9})', string=all_of_thundercat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicates in thundercat lyrics list\n",
    "\n",
    "thundercat_songlinks = list(dict.fromkeys(thundercat_songlinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to thundercat lyrics\n",
    "\n",
    "thundercat_songlinks_final = [\"www.lyrics.com/\" + x for x in thundercat_songlinks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut list short to first 100 songs\n",
    "\n",
    "thundercat_songlinks_final = thundercat_songlinks_final[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download lyrics\n",
    "\n",
    "for songlink in thundercat_songlinks_final:\n",
    "    song_number = re.findall(pattern='(\\d{6,9})', string=songlink)\n",
    "    print(songlink)\n",
    "    f = open(f\"thundercat_lyrics/{song_number}.txt\", \"w\")\n",
    "    song_html = requests.get(songlink).text\n",
    "    f.write(song_html)\n",
    "    f.close()\n",
    "    print (song_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put lyrics into list\n",
    "\n",
    "thundercat_lyrics = []\n",
    "\n",
    "for fn in os.listdir('thundercat_lyrics/'):\n",
    "     text = open('thundercat_lyrics/' + fn).read()\n",
    "     thundercat_soup = BeautifulSoup(text, 'html.parser')\n",
    "     #print (thundercat_soup.type)\n",
    "     lyric = thundercat_soup.find_all('pre',{\"class\":\"lyric-body\"})\n",
    "     thundercat_lyrics.append(lyric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up lyrics in list\n",
    "\n",
    "cleaner = re.compile('<.*?>') \n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleantext = re.sub(cleaner, '', raw_html)\n",
    "  return cleantext\n",
    "\n",
    "thundercat_lyrics_clean = []\n",
    "\n",
    "for x in thundercat_lyrics:\n",
    "    x_clean = cleanhtml(str(x))\n",
    "    x_clean = re.sub('[^A-Za-z\\s]+', '', x_clean)\n",
    "    thundercat_lyrics_clean.append(x_clean.lower().replace('\\n', ' ').replace(\"\\'\", \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining lyrics to corpus, tokenizing and lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all lyrics\n",
    "\n",
    "corpus = thundercat_lyrics_clean + gaga_lyrics_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download nltk - package\n",
    "\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and lemmatize the corpus\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "clean_corpus = []\n",
    "\n",
    "for doc in corpus:\n",
    "    tokens = tokenizer.tokenize(text=doc)\n",
    "    clean_doc = \" \".join(lemmatizer.lemmatize(token) for token in tokens)\n",
    "    clean_corpus.append(clean_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stopwords list\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "\n",
    "LABELS = [\"Thundercat\"] * 50 + [\"Lady Gaga\"] * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "\n",
    "steps = [\n",
    "          ('tf-idf', TfidfVectorizer(stop_words=STOPWORDS)),        \n",
    "          ('LR', MultinomialNB())\n",
    "        ]\n",
    "\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pipeline on data\n",
    "\n",
    "pipeline.fit(clean_corpus, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function, csv-export and model-export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to give probablity of lyric\n",
    "\n",
    "def give_artist(lyric):\n",
    "    if not lyric:\n",
    "        return \"You did not give an input\"\n",
    "    probab = pipeline.predict_proba([lyric])\n",
    "    who_wrote = pipeline.predict([lyric])[0]\n",
    "    func_return = \"This was probably written by: \" + who_wrote\n",
    "    if who_wrote == \"Lady Gaga\":\n",
    "        func_return = func_return + \" , with a certainty of: \" + str(round(100*probab[0][0])) + \"%\"\n",
    "    else:\n",
    "        func_return = func_return + \" , with a certainty of: \" + str(round(100*probab[0][1])) + \"%\"\n",
    "    return str(func_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export clean_corpus\n",
    "\n",
    "file = open('clean_corpus.csv', 'w+', newline ='') \n",
    "with file:\n",
    "    for lyrics in clean_corpus:     \n",
    "        lyric = lyrics.split(',')\n",
    "        write = csv.writer(file) \n",
    "        write.writerow(lyric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model\n",
    "\n",
    "model_export = pipeline.fit(clean_corpus, LABELS)\n",
    "with open(\"naive_classifier.bin\", \"wb\") as file:\n",
    "    pickle.dump(NB_clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abc7d9422c788b1f325554a74823655484f1a6b478c1481f1f9705007e56709b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
